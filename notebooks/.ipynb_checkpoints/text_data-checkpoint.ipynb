{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8109a91e-7cf6-4f97-8568-0860d819b788",
   "metadata": {},
   "source": [
    "# Text Data Exploration"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c72c264-49f2-41f8-8218-6633e44aa076",
   "metadata": {},
   "source": [
    "Here we will explore the text data contained in the dataset \"AI vs Himan Text\"\n",
    "\n",
    "The dataset is in .zip format and we will try to keep it as is"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "01eb96ac-39be-4000-a431-b21f68f224bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import basic packages\n",
    "\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "import os\n",
    "import pickle\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from tqdm import tqdm\n",
    "import shutil\n",
    "import tempfile\n",
    "import psutil  # For memory monitoring\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5c8588de-7d04-4ae5-978d-0b281446592b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the paths to the files to import\n",
    "text ='/home/antonio/code/aferri-git/AI-Detector-project/AI-Detector-interface/raw_data/AI_Vs_Human_Text.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b1b51f72-85c8-41a5-8862-14450f53a65f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the file\n",
    "\n",
    "text_df = pd.read_csv(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b8366f54-5823-4c8f-abed-216950057d67",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>generated</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Cars. Cars have been around since they became ...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Transportation is a large necessity in most co...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>\"America's love affair with it's vehicles seem...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>How often do you ride in a car? Do you drive a...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Cars are a wonderful thing. They are perhaps o...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  generated\n",
       "0  Cars. Cars have been around since they became ...        0.0\n",
       "1  Transportation is a large necessity in most co...        0.0\n",
       "2  \"America's love affair with it's vehicles seem...        0.0\n",
       "3  How often do you ride in a car? Do you drive a...        0.0\n",
       "4  Cars are a wonderful thing. They are perhaps o...        0.0"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Visualize the dataframe\n",
    "\n",
    "text_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ae8e5f2e-8278-4c0a-92dd-97549867eb54",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 487235 entries, 0 to 487234\n",
      "Data columns (total 2 columns):\n",
      " #   Column     Non-Null Count   Dtype  \n",
      "---  ------     --------------   -----  \n",
      " 0   text       487235 non-null  object \n",
      " 1   generated  487235 non-null  float64\n",
      "dtypes: float64(1), object(1)\n",
      "memory usage: 7.4+ MB\n"
     ]
    }
   ],
   "source": [
    "# Information about the dataframe\n",
    "\n",
    "text_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ed8c663a-e1dd-4e33-abc1-480fa1c89f0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generated\n",
      "0.0    305797\n",
      "1.0    181438\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Count the number of text generated by AI (1) or human (0)\n",
    "\n",
    "class_counts = text_df['generated'].value_counts()\n",
    "print(class_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "4395d61e-f5ec-4282-95f5-8d5317ba7701",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: xlabel='generated', ylabel='count'>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.countplot(data=text_df,x='generated')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1549086d-e1d4-45e6-b107-119b3043f725",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Establish the ration\n",
    "\n",
    "ratio = class_counts[0]/class_counts[1]\n",
    "print(f\"Ratio: {ratio:.2f}:1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9669b88a-a77c-4e61-b986-6e7388c768e1",
   "metadata": {},
   "source": [
    "The dataset is relatively imbalanced (63/37); this may favour correct scoring of the most present class. \n",
    "from here there are a few options:\n",
    "1) use resampling techniques such as SMOTE to correct for the imbalance -> introduce some artificiality\n",
    "2) extract a subsample of the category 0 which matches the size of category 1 -> loss of data (25%)\n",
    "3) leave the dataset as is and observe performance of the model on the minority class. you can always  apply techniques such as class weighting later to mitigate imbalance\n",
    "\n",
    "we will go for option 2 because the full dataset is too big for this machine and has caused problem when preprocessing using the full sample size"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ecb1472-9b6f-4f06-9485-f8608174c933",
   "metadata": {},
   "source": [
    "# Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec51598b-b32c-465f-b183-7d4aa38336b2",
   "metadata": {},
   "source": [
    "Here we will perform all the data pre processing needed for NLP models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa5f58a5-0869-4a8a-99e2-5ec25f1b51ee",
   "metadata": {},
   "source": [
    "## Intermediate steps"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10067692-8b6f-4b78-9a74-581aa16b5463",
   "metadata": {},
   "source": [
    "The pipeline will be computationally intensive given the size of the dataset.\n",
    "To address this it's best to save each intermediate step as a pickle file "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f435d67d-fca7-4e1a-b113-8cf41098526f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to save DataFrame\n",
    "\n",
    "def save_dataframe(df, filepath, compression='infer'):\n",
    "    try:\n",
    "        df.to_pickle(filepath, compression=compression)\n",
    "        print(f\"Saved: {filepath}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Failed to save {filepath}: {e}. Retrying without compression...\")\n",
    "        try:\n",
    "            df.to_pickle(filepath, compression=None)\n",
    "            print(f\"Saved without compression: {filepath}\")\n",
    "        except Exception as e:\n",
    "            print(f\"Retry failed: {e}. Skipping save.\")\n",
    "            raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2e876eaf-0b7d-477e-bb45-ad9e0e4a9d23",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Define file paths relative to raw_data folder (one directory up)\n",
    "raw_data_dir = os.path.abspath(os.path.join(os.getcwd(), '..', 'raw_data'))\n",
    "\n",
    "os.makedirs(raw_data_dir, exist_ok=True)  # Create raw_data if it doesn't exist\n",
    "\n",
    "file_paths = {\n",
    "    'balanced': os.path.join(raw_data_dir, 'text_balanced.pkl'),\n",
    "    'cleaned': os.path.join(raw_data_dir, 'text_cleaned.pkl'),\n",
    "    'tokenized': os.path.join(raw_data_dir, 'text_tokenized.pkl'),\n",
    "    'stopwords': os.path.join(raw_data_dir, 'text_stopwords.pkl'),\n",
    "    'final': os.path.join(raw_data_dir, 'text_final.pkl') # Final output (stopwords removed + lemma|tized)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c4f26bd9-243c-445a-a6c0-3476c8a9a32e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to load DataFrame if it exists, with a built-in error handler\n",
    "\n",
    "def load_if_exists(filepath):\n",
    "    if os.path.exists(filepath):\n",
    "        print(f\"Loading existing file: {filepath}\")\n",
    "        try:\n",
    "            df = pd.read_pickle(filepath)\n",
    "            print(f\"Successfully loaded {filepath}\")\n",
    "            return df\n",
    "        except (EOFError, ValueError, pickle.UnpicklingError) as e:\n",
    "            print(f\"Error loading {filepath}: {e}. Deleting corrupted file and reprocessing.\")\n",
    "            try:\n",
    "                os.remove(filepath)\n",
    "                print(f\"Deleted: {filepath}\")\n",
    "            except OSError as e:\n",
    "                print(f\"Failed to delete {filepath}: {e}\")\n",
    "            return None\n",
    "    return None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30725ace-3549-47c0-8ebc-e13876785732",
   "metadata": {},
   "source": [
    "## Balancing classes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "424dfb33-4a2d-4d71-8789-b7f1b08e2747",
   "metadata": {},
   "source": [
    "We will use a function to balance the classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b442d82c-e37c-444f-b1e9-f2088279a5d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function will extract a random sample equal to the minority class size for the dominant class, combine them and shuffle them\n",
    "\n",
    "def balance_classes(text_df, class_column='generated', target_size=None):\n",
    "    text_final = load_if_exists(file_paths['final'])\n",
    "    \n",
    "    if text_final is not None:\n",
    "        print(\"Skipping balancing (final file exists).\")\n",
    "        return text_final  # Return final dataframe if it exists\n",
    "    \n",
    "    text_balanced = load_if_exists(file_paths['balanced'])\n",
    "    if text_balanced is None:\n",
    "        print(\"Balancing classes...\")\n",
    "        class_0 = text_df[text_df['generated'] == 0.0]\n",
    "        class_1 = text_df[text_df['generated'] == 1.0]\n",
    "        class_0_sampled = class_0.sample(n=181438, random_state=42)\n",
    "        text_balanced = pd.concat([class_0_sampled, class_1])\n",
    "        save_dataframe(text_balanced, file_paths['balanced'])\n",
    "    else:\n",
    "        print(\"Skipping balancing (loaded from file).\")\n",
    "    \n",
    "    return text_balanced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "97376818-66e0-403a-87b9-3e230bd84a7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Balancing classes...\n",
      "Saved: /home/antonio/code/aferri-git/AI-Detector-project/AI-Detector-interface/raw_data/text_balanced.pkl\n"
     ]
    }
   ],
   "source": [
    "text_balanced = balance_classes(text_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f7d9ee6e-4d5a-4b81-98b2-9197e6b40285",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 362876 entries, 260481 to 487232\n",
      "Data columns (total 2 columns):\n",
      " #   Column     Non-Null Count   Dtype  \n",
      "---  ------     --------------   -----  \n",
      " 0   text       362876 non-null  object \n",
      " 1   generated  362876 non-null  float64\n",
      "dtypes: float64(1), object(1)\n",
      "memory usage: 8.3+ MB\n"
     ]
    }
   ],
   "source": [
    "text_balanced.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c920f347-ca18-4363-823f-20f714ad0d9d",
   "metadata": {},
   "source": [
    "### Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "45b58296-8a23-4c7b-9e28-b2e2b78fd768",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to handle the cleaning\n",
    "    # Try to load the cleaned dataframe; f it does not exist,import the basic df\n",
    "    # Apply .strip and .lower methodologies to the text column of the df\n",
    "    # Remove numbers and symbols to ensure better text clustering and keyphrases collection\n",
    "\n",
    "def cleaning(text_balanced, file_paths):\n",
    "    text_final = load_if_exists(file_paths['final'])\n",
    "    \n",
    "    if text_final is not None:\n",
    "        print(\"Skipping cleaning (final file exists).\")\n",
    "        return text_final  # Return final dataframe if it exists\n",
    "    \n",
    "    text_cleaned = load_if_exists(file_paths['cleaned'])\n",
    "    if text_cleaned is None:\n",
    "        print(\"Cleaning balanced dataset...\")\n",
    "        # Use text_balanced directly (362,876 rows from balance_classes)\n",
    "        text_cleaned = text_balanced.copy()  # Avoid modifying input\n",
    "        \n",
    "        # Apply cleaning operations\n",
    "        text_cleaned['text'] = text_cleaned['text'].str.strip()\n",
    "        text_cleaned['text'] = text_cleaned['text'].str.lower()\n",
    "        text_cleaned['text'] = text_cleaned['text'].str.replace(r'[^a-zA-Z\\s]', \"\", regex=True)\n",
    "        \n",
    "        # Save cleaned DataFrame\n",
    "        save_dataframe(text_cleaned, file_paths['cleaned'])\n",
    "    else:\n",
    "        print(\"Skipping cleaning (loaded from file).\")\n",
    "\n",
    "    return text_cleaned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7a363123-f326-466e-9f2e-421a0811f1cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaning balanced dataset...\n",
      "Saved: /home/antonio/code/aferri-git/AI-Detector-project/AI-Detector-interface/raw_data/text_cleaned.pkl\n"
     ]
    }
   ],
   "source": [
    "text_cleaned = cleaning(text_balanced, file_paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6ec04032-37bb-4615-b8a9-78117701a9d8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "260481    do curfews keep teenagers from getting into tr...\n",
       "133303    in this article the challenge of exploring ven...\n",
       "291551    with thp rapid growth of thp internet in recen...\n",
       "451335    the electoral college is the way us united sta...\n",
       "461660    this technology of you can calculate the emoti...\n",
       "438750    how would you feel if i knew your emotions all...\n",
       "276176    the face on mars had no alien help to be forme...\n",
       "486953    the challenge of exploring venus suggests that...\n",
       "164845    i am going to prove that the face you saw on t...\n",
       "464668    in the article the challenge of exploring venu...\n",
       "103726    although some say failure doesnt play in the p...\n",
       "367339    the making of the facs was not too good of an ...\n",
       "328296    thomas jefferson once said determine never to ...\n",
       "466710    i think that would bf totally stupid to do tha...\n",
       "375784    if ws think about ths words that ths british p...\n",
       "97767     our principal has decided that all students mu...\n",
       "356121    dear principle\\n\\ni think that your idea for p...\n",
       "100621    in this essay i will be describing why its imp...\n",
       "482226    deal senator of state\\n\\nn think keeping elect...\n",
       "431892    dear our beloved principal\\n\\ni would just lik...\n",
       "Name: text, dtype: object"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# let's check the output so far\n",
    "\n",
    "text_cleaned['text'].head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b4edf1d6-211a-4e09-909c-cf18eb1120a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 362876 entries, 260481 to 487232\n",
      "Data columns (total 2 columns):\n",
      " #   Column     Non-Null Count   Dtype  \n",
      "---  ------     --------------   -----  \n",
      " 0   text       362876 non-null  object \n",
      " 1   generated  362876 non-null  float64\n",
      "dtypes: float64(1), object(1)\n",
      "memory usage: 8.3+ MB\n"
     ]
    }
   ],
   "source": [
    "text_cleaned.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f3c4d83a-d74a-4220-9f95-560ecdd714c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove all the whitespaces at the beginning and the end of a string and change all letters to lowe case\n",
    "\n",
    "#text_cleaned = text_df.copy()\n",
    "\n",
    "#text_cleaned['text'] = text_cleaned['text'].str.strip()\n",
    "#text_cleaned['text'] = text_cleaned['text'].str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "43a0fdce-ef7f-463c-93fe-5dfe57b51135",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove numbers and symbols to ensure better text clustering and keyphrases collection\n",
    "# replace(r'[^a-zA-Z\\s]')\n",
    "# a-zA-Z: Matches all lowercase (a-z) and uppercase (A-Z) alphabetic characters\n",
    "# \\s: Matches any whitespace character (space, tab, newline)\n",
    "# [^...]: Matches anything NOT included in the brackets. This removes everything that isn't a letter or whitespace\n",
    "\n",
    "# text_cleaned['text'] = text_cleaned['text'].str.replace(r'[^a-zA-Z\\s]', \"\", regex=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a050a0c7-2da2-41a9-8ef1-86c764223f5c",
   "metadata": {},
   "source": [
    "## Tokenizing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3d5193b0-e7b3-4870-83c5-ed4c55aaee4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The next function has had some crassing issues so I divide the work in chunks and I use psutil to have insight over SSD usage\n",
    "\n",
    "def print_disk_usage():\n",
    "    usage = shutil.disk_usage('.')\n",
    "    print(f\"Disk usage: {usage.used / 1024**3:.2f}/{usage.total / 1024**3:.2f} GB, Free: {usage.free / 1024**3:.2f} GB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "fad6a649-5dfc-4413-b7c3-1b55fefa6f83",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The next function has had some crassing issues so I divide the work in chunks and I use psutil to have insight over memory usage\n",
    "def print_memory_usage():\n",
    "    process = psutil.Process()\n",
    "    mem_info = process.memory_info()\n",
    "    print(f\"Memory usage: {mem_info.rss / 1024**2:.2f} MB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c2d7f6f2-4202-48dc-8dd5-dfa4ccd8d9f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to handle the tokenization\n",
    "    # Try to load the tokenized dataframe; f it does not exist, copy the cleaned_df \n",
    "    # Apply .strip and .lower methodologies to the text column of the df\n",
    "    # Remove numbers and symbols to ensure better text clustering and keyphrases collection\n",
    "    # This step cannot be saved in a pkl because it crashes the kernel. It is the save_dataframe function; I have tried with different\n",
    "    # formats but it did not change so I will remove the load and save portions\n",
    "\n",
    "def tokenization(text_cleaned, file_paths):\n",
    "    text_final = load_if_exists(file_paths['final'])\n",
    "    \n",
    "    if text_final is not None:\n",
    "        print(\"Skipping tokenization (final file exists).\")\n",
    "        return text_final\n",
    "    else:\n",
    "        print(\"Preparing tokenization...\")\n",
    "        text_tokenized = text_cleaned.copy()\n",
    "        text_tokenized['text'] = (\n",
    "            text_tokenized['text']\n",
    "            .str.replace(r'\\s+', ' ', regex=True)\n",
    "            .str.strip()\n",
    "            .str.split()\n",
    "        )\n",
    "        return text_tokenized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "635e8519-d2e1-4492-8801-7314484d2fa9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preparing tokenization...\n"
     ]
    }
   ],
   "source": [
    "text_tokenized = tokenization(text_cleaned, file_paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b1d90263-0e1f-43d9-9f8f-8e4721acbcc3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "260481    [do, curfews, keep, teenagers, from, getting, ...\n",
       "Name: text, dtype: object"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_tokenized['text'].head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ca733863-0fd9-49f5-811d-e94cdefcee4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 362876 entries, 260481 to 487232\n",
      "Data columns (total 2 columns):\n",
      " #   Column     Non-Null Count   Dtype  \n",
      "---  ------     --------------   -----  \n",
      " 0   text       362876 non-null  object \n",
      " 1   generated  362876 non-null  float64\n",
      "dtypes: float64(1), object(1)\n",
      "memory usage: 8.3+ MB\n"
     ]
    }
   ],
   "source": [
    "text_tokenized.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "06be397b-4364-4199-80e8-1dceaf73a42f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a copy of the dataframe on which we apply the preprocessing\n",
    "\n",
    "# text_tokenized = text_cleaned.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "e0c793db-5aed-4ea8-8f5f-494bd40ece0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize whitespace and tokenize\n",
    "#  In this case we do not need to use word_tokenize from nltk.tokenize because the text is simple and contains\n",
    "#  no symbols or anything complex and applying that method will require too much time. .split will do once we normalize spaces\n",
    "#  spaces need to be normalized because we might have several consecutive ones after removing several symbols\n",
    "\n",
    "#text_tokenized['text'] = text_tokenized['text'].str.replace(r'\\s+', ' ', regex=True).str.strip()\n",
    "#text_tokenized['text'] = text_tokenized['text'].str.split()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f092ee3-95ad-4d0c-8288-229bbd8755a8",
   "metadata": {},
   "source": [
    "## Stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "66772c9b-24ec-42be-80f6-57d57becda57",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defines a function to remove defined stopwords\n",
    "#   Uses nltk.corpus to define stopwords\n",
    "#   Iterates over each word (alredy tokenized) to filter out stopwords\n",
    "\n",
    "def remove_stopwords(text_tokenized, file_paths):\n",
    "    text_final = load_if_exists(file_paths['final'])\n",
    "    \n",
    "    if text_final is not None:\n",
    "        print(\"Skipping stopwords removal (final file exists).\")\n",
    "        return text_final  # Return final dataframe if it exists\n",
    "    \n",
    "    text_stopwords = load_if_exists(file_paths['stopwords'])\n",
    "    if text_stopwords is None:\n",
    "        print(\"Preparing stopwords...\")\n",
    "        text_stopwords = text_tokenized.copy()\n",
    "        stop_words = set(stopwords.words('english'))\n",
    "        text_stopwords['text'] = text_stopwords['text'].apply(\n",
    "            lambda tokens: [word for word in tokens if word.lower() not in stop_words]\n",
    "        )\n",
    "        save_dataframe(text_stopwords, file_paths['stopwords'])\n",
    "    else:\n",
    "        print(\"Skipping stopwords (loaded from file).\")\n",
    "    \n",
    "    return text_stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "4356d1b1-1f42-4c54-a011-9b49d79e1fe1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preparing stopwords...\n",
      "Saved: /home/antonio/code/aferri-git/AI-Detector-project/AI-Detector-interface/raw_data/text_stopwords.pkl\n"
     ]
    }
   ],
   "source": [
    "text_stopwords = remove_stopwords(text_tokenized, file_paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "5935d92f-c15d-4461-99f6-b4ca870e84ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenized Lenght:  138240589\n",
      "Stopwords Lenght:  74181069\n"
     ]
    }
   ],
   "source": [
    "# Check for lenght differences to verify stopwords removal\n",
    "tokenized_lenght = text_tokenized['text'].apply(len)\n",
    "stopwords_lenght = text_stopwords['text'].apply(len)\n",
    "\n",
    "print('Tokenized Lenght: ', tokenized_lenght.sum())\n",
    "print('Stopwords Lenght: ', stopwords_lenght.sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "487d3b64-4dbc-4d59-8fea-9bf030002412",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a copy of the dataframe on which we apply the preprocessing\n",
    "\n",
    "#text_stopwords = text_tokenized.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "6f5137d7-e583-4a54-ace6-9f281d8c07d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply the function\n",
    "\n",
    "#text_stopwords['text'] = text_stopwords['text'].apply(remove_stopwords)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "115795bc-ef42-4e01-bd1a-a512ed9da88c",
   "metadata": {},
   "source": [
    "## Lemmatizing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "4ce88aa8-dd49-4074-b838-b72e0c9a9d1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defines a function to lemmatize text\n",
    "#   Uses WordNetLemmatizer to define the lemmatization scheme\n",
    "#   Iterates over each word (alredy tokenized) to apply lemmatization\n",
    "\n",
    "def lemmatize_tokens(text_stopwords, file_paths):\n",
    "    text_final = load_if_exists(file_paths['final'])\n",
    "    \n",
    "    if text_final is None:\n",
    "        print(\"Preparing final dataframe...\")\n",
    "        text_final = text_stopwords.copy()\n",
    "        lemmatizer = WordNetLemmatizer()\n",
    "        text_final['text'] = text_final['text'].apply(\n",
    "            lambda tokens: [lemmatizer.lemmatize(word) for word in tokens]\n",
    "        )\n",
    "        save_dataframe(text_final, file_paths['final'])\n",
    "    else:\n",
    "        print(\"Skipping lemmatization (loaded from file).\")\n",
    "    \n",
    "    return text_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "68ace52d-86e5-4778-8dc6-161932bf0821",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preparing final dataframe...\n",
      "Saved: /home/antonio/code/aferri-git/AI-Detector-project/AI-Detector-interface/raw_data/text_final.pkl\n"
     ]
    }
   ],
   "source": [
    "text_final = lemmatize_tokens(text_stopwords, file_paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "a54a25a0-d7f4-478c-9162-5af8e4336e27",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a copy of the dataframe on which we apply the preprocessing\n",
    "\n",
    "#text_lemmatize = text_stopwords.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "8c75c029-bab0-4ce4-968c-65fe8e9e0d0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply the function\n",
    "\n",
    "#text_lemmatize['text'] = text_lemmatize['text'].apply(lemmatize_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "8a3f7ab7-8644-46c8-9743-1700950b227a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Are the original and lemmatized tokens equal? False\n"
     ]
    }
   ],
   "source": [
    "# Check if lemmatization actually changed any tokens by comparing original and lemmatized text for the first row\n",
    "\n",
    "is_equal = text_tokenized['text'].iloc[0] == text_final['text'].iloc[0]\n",
    "print(f\"Are the original and lemmatized tokens equal? {is_equal}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "09e1d90b-3146-4054-9f98-04869586c069",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function will remove all the intermediate pkl steps, except the final one\n",
    "\n",
    "\n",
    "def cleanup_intermediate_files(file_paths):\n",
    "    print(\"Removing intermediate .pkl files...\")\n",
    "    for key, filepath in file_paths.items():\n",
    "        if key != 'final' and filepath.endswith('.pkl') and os.path.exists(filepath):\n",
    "            try:\n",
    "                os.remove(filepath)\n",
    "                print(f\"Deleted: {filepath}\")\n",
    "            except OSError as e:\n",
    "                print(f\"Failed to delete {filepath}: {e}\")\n",
    "    print(\"Cleanup complete.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "e117101c-7f3a-4478-b557-98ddb40d4e3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removing intermediate .pkl files...\n",
      "Deleted: /home/antonio/code/aferri-git/AI-Detector-project/AI-Detector-interface/raw_data/text_balanced.pkl\n",
      "Deleted: /home/antonio/code/aferri-git/AI-Detector-project/AI-Detector-interface/raw_data/text_cleaned.pkl\n",
      "Deleted: /home/antonio/code/aferri-git/AI-Detector-project/AI-Detector-interface/raw_data/text_stopwords.pkl\n",
      "Cleanup complete.\n"
     ]
    }
   ],
   "source": [
    "cleanup_intermediate_files(file_paths)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa2471b0-cfd4-43d8-b47a-a78963315653",
   "metadata": {},
   "source": [
    "# Models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2407b973-1fc7-4f57-ab7a-2a27979e3119",
   "metadata": {},
   "source": [
    "## Train Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5f203164-3fd9-4d96-8071-1ace32399609",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading existing file: /home/antonio/code/aferri-git/AI-Detector-project/AI-Detector-interface/raw_data/text_final.pkl\n",
      "Successfully loaded /home/antonio/code/aferri-git/AI-Detector-project/AI-Detector-interface/raw_data/text_final.pkl\n"
     ]
    }
   ],
   "source": [
    "text_final = load_if_exists(file_paths['final'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "190babd4-a3bc-466e-9dc0-8a8b076a56b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A function that splits the data into train and test datasets. This funciton is ran before any additional steps\n",
    "# to avoid any data leak\n",
    "\n",
    "def split_data(text_final, test_size, random_state):\n",
    "    \n",
    "    X = text_final['text'].apply(' '.join)  # Join tokens for vectorization\n",
    "    y = text_final['generated']\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size, random_state=random_state)\n",
    "    \n",
    "    return X_train, X_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ff300a72-c975-4ba6-b2c8-822980c7bbe3",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_sze = 0.2\n",
    "random_state =42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d1d343f0-0ab2-468c-a498-a1b1effb659a",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = split_data(text_final, test_sze, random_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a303d92f-74b5-47e0-83ae-db4f570f1342",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.series.Series'>\n",
      "Index: 290300 entries, 399653 to 391747\n",
      "Series name: text\n",
      "Non-Null Count   Dtype \n",
      "--------------   ----- \n",
      "290300 non-null  object\n",
      "dtypes: object(1)\n",
      "memory usage: 4.4+ MB\n"
     ]
    }
   ],
   "source": [
    "X_train.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "428d3382-d34a-46b1-82dd-063a93f854d9",
   "metadata": {},
   "source": [
    "## Baseline Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d5b25b1-6e94-4ac1-b59b-a193aa626a39",
   "metadata": {},
   "source": [
    "### Vectorization\n",
    "\n",
    "Through vectorization we translate words into numbers. There are diferent types of approaches to this, but we will use the simplest one to pair with our baseline model: \"Bag-of-words\" using TfidfVectorizer.\n",
    "\n",
    "TfidfVectorizer is superior to CountVectorizer in this instance because it weights rare terms higher, which can account for nuanced differences between human and AI generated text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4daf4f10-64ed-40e4-b88b-1ccc4f2975e6",
   "metadata": {},
   "source": [
    "## Logistic Regression\n",
    "\n",
    "As a baseline model, the first choice is the Logistic Regression. It's fast and simple to interpret\n",
    "\n",
    "This model may however struggle with complex, non linear relationships. A more advanced ML model might be required"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2a28d2fd-dce7-4b9e-86f4-800e6997c5f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build a pipeline for the vectorization and baseline model \n",
    "\n",
    "model = make_pipeline(TfidfVectorizer(), LogisticRegression(max_iter=1000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "cac67511-78f7-49fe-afdb-19927ca635e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: #000;\n",
       "  --sklearn-color-text-muted: #666;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-1 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-1 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: flex;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "  align-items: start;\n",
       "  justify-content: space-between;\n",
       "  gap: 0.5em;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label .caption {\n",
       "  font-size: 0.6rem;\n",
       "  font-weight: lighter;\n",
       "  color: var(--sklearn-color-text-muted);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-1 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-1 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-1 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 0.5em;\n",
       "  text-align: center;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-1 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Pipeline(steps=[(&#x27;tfidfvectorizer&#x27;, TfidfVectorizer()),\n",
       "                (&#x27;logisticregression&#x27;, LogisticRegression(max_iter=1000))])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>Pipeline</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.6/modules/generated/sklearn.pipeline.Pipeline.html\">?<span>Documentation for Pipeline</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></div></label><div class=\"sk-toggleable__content fitted\"><pre>Pipeline(steps=[(&#x27;tfidfvectorizer&#x27;, TfidfVectorizer()),\n",
       "                (&#x27;logisticregression&#x27;, LogisticRegression(max_iter=1000))])</pre></div> </div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>TfidfVectorizer</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.6/modules/generated/sklearn.feature_extraction.text.TfidfVectorizer.html\">?<span>Documentation for TfidfVectorizer</span></a></div></label><div class=\"sk-toggleable__content fitted\"><pre>TfidfVectorizer()</pre></div> </div></div><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>LogisticRegression</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.6/modules/generated/sklearn.linear_model.LogisticRegression.html\">?<span>Documentation for LogisticRegression</span></a></div></label><div class=\"sk-toggleable__content fitted\"><pre>LogisticRegression(max_iter=1000)</pre></div> </div></div></div></div></div></div>"
      ],
      "text/plain": [
       "Pipeline(steps=[('tfidfvectorizer', TfidfVectorizer()),\n",
       "                ('logisticregression', LogisticRegression(max_iter=1000))])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit the model on the train dataset\n",
    "\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d028e9ae-dc86-44e4-88a6-e76a30b64e07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      0.99      0.99     36280\n",
      "         1.0       0.99      0.99      0.99     36296\n",
      "\n",
      "    accuracy                           0.99     72576\n",
      "   macro avg       0.99      0.99      0.99     72576\n",
      "weighted avg       0.99      0.99      0.99     72576\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Evaluate\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9c6cc55-a061-4146-bb63-a54bf7ae876c",
   "metadata": {},
   "source": [
    "The classification reports shows suspiciously high metrics; there are two possible explanations for this:\n",
    "\n",
    "1) data leakage has occurred\n",
    "2) there are distinct linear differences between human and AI generate text which are easily picked up by simple models\n",
    "\n",
    "Since the train test split has been performed before fitting the dataset on the vectorization or the model, data leakage could not have occurred. To verify this, we can apply cross validation accross data splits to assess if the performance is consistent. It will tell us how well the model generalizes on unseen data by scoring each fold\n",
    "\n",
    "Cros Validation does not require prior train_test split. It will take care of that itself. This will also rule out potential data leakages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "92bc7c23-41fa-473c-8820-ad9ca4c6ea7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_model = make_pipeline(TfidfVectorizer(), LogisticRegression(max_iter=1000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "76375405-2014-4684-a349-b37ffad27e72",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_folds = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b730082e-0038-4d74-b807-21b23b51f4c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = cross_val_score(model, text_final['text'].apply(' '.join), text_final['generated'], cv=n_folds, scoring='f1_macro')\n",
    "\n",
    "print(f\"Cross-validation F1 scores: {scores.mean():.2f}  {scores.std():.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19097479-25a8-4b9c-8635-c4b1ad23c0a4",
   "metadata": {},
   "source": [
    "The results are the same and the data has been already shuffled when balancing classess. It seems the model can predict well this datase\n",
    "\n",
    "The last thing left to check is the dataset. Are the sourcing done all from oen place per class? (i.e. human from reddit and AI from chatgpt). If that's the case I am modelling for data source\n",
    "\n",
    "On the dataset page available at https://www.kaggle.com/datasets/shanegerami/ai-vs-human-text it is stated that the dataset is collected form different sources and there are no douplicates; I will be working on the assumption that this is indeed true to move on with the project\n",
    "\n",
    "I would however consider as a next step to collect AI generated text from other sources as it could all be from a unique model"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "AI-Detector-interface",
   "language": "python",
   "name": "ai-detector-interface"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
